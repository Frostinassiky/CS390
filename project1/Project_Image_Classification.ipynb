{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quHwuvnL_N9o"
   },
   "source": [
    "# Project 1: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JWfOd3AVO9J"
   },
   "source": [
    "## Task 0: Getting Started\n",
    "\n",
    "Read the getting started guide titled **\"Python for Deep Learning\"** and get familiar with Python and PyTorch. Read the provided code below and get familiar with the commands and their parameters to understand what the code is trying to do. We recommend to spend a fair amount of time to understand all the different parts of the code. This understanding will be important for this and future projects.\n",
    "\n",
    "The goal of this project is to implement the *“Hello World!”* program of deep learning: designing and training a network that performs image classification. The dataset we will be using is CIFAR10 which is a large set of images that are classified into 10 classes (airplane, bird, cat, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wgsyd2YsVO9L"
   },
   "source": [
    "## Task 1:  Data Loading (10 points)\n",
    "Complete the **DataLoader** below which we will use to load images of the cifar10 dataset provided by torchvision. Your task is to normalize it by shifting and scaling it by a factor of 0.5. For the training set, introduce random transformations (e.g. flips) for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtxYeHjRVO9S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for testing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "    # TODO Task 1:  Training transofrmations\n",
    "        # transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "    # TODO Task 1:  Test transofrmations\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load CIFAR10\n",
    "image_datasets = {x: torchvision.datasets.CIFAR10(root='./data', train=(x=='train'), download=True, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=(x=='train'), num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS6cR4RhVO9U"
   },
   "source": [
    "### Visualize a few images\n",
    "\n",
    "Let’s visualize a few training images so as to understand the data augmentations. The results should look like:\n",
    "\n",
    "<img src=\"https://i.imgur.com/Sa6l1go.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXSA5DDBVO9V"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Task 1:  Run this cell and try to understand the output of each step\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmMMSK0TVO9L"
   },
   "source": [
    "## Task 2: Basic Networks (20 points)\n",
    "1. Create a Fully connected Network (FcNet) as follows in the Jupyter Notebook:\n",
    "```\n",
    "FcNet(\n",
    "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
    "  (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
    "  (fc3): Linear(in_features=400, out_features=84, bias=True)\n",
    "  (fc4): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the FcNet for **3** epoches and record the training time and accuracy in your final report.\n",
    "\n",
    "2. Create a Convolutional Network (ConvNet) as follows in the Jupyter Notebook:\n",
    "```\n",
    "ConvNet(\n",
    "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the ConvNet for **3** epoches and record the training time and accuracy in your final report. \n",
    "\n",
    "*Use the default SGD optimizer ( lr=0.001, momentum=0.9) for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sKXg8fSVO9X"
   },
   "source": [
    "### Model training code (do not modify except for plotting the loss curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_Y2cgPEVO9X"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, save_path='saved_weight.pth'):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train': model.train()  # Set model to training mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX6I8cqXFDMX"
   },
   "source": [
    "### 1) FC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpompN92VO9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FcNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=400, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=400, out_features=84, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1) Define a Fully Connected Neural Network\n",
    "class FcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FcNet, self).__init__()\n",
    "        # TODO Task 2:  Define the layers \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=3072, out_features=1024, bias=True), nn.ReLU(), \n",
    "            nn.Linear(in_features=1024, out_features=400, bias=True), nn.ReLU(), \n",
    "            nn.Linear(in_features=400, out_features=84, bias=True), nn.ReLU(), \n",
    "            nn.Linear(in_features=84, out_features=10, bias=True),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        # print(x.shape)\n",
    "        b,c,w,h=x.shape\n",
    "        x = self.layers(x.view(b,-1))\n",
    "        return x\n",
    "\n",
    "model_ft = FcNet()\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 1.6920 Acc: 0.3953\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 1.4434 Acc: 0.4878\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 1.3388 Acc: 0.5233\n",
      "\n",
      "Training complete in 1m 49s\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFQdcJaKFF8y"
   },
   "source": [
    "### 2) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ma36XwVfVO9h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (4): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 2) Define a Convolutional Neural Network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # TODO Task 2:  Define the CNN layers \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "            nn.Linear(in_features=400, out_features=120, bias=True),\n",
    "            nn.Linear(in_features=120, out_features=84, bias=True),\n",
    "            nn.Linear(in_features=84, out_features=10, bias=True),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        self.layers(x)\n",
    "        return x\n",
    "\n",
    "model_ft = ConvNet()\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [640 x 10], m2: [400 x 120] at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THC/generic/THCTensorMathBlas.cu:273",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5a63e7303a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9d20c247c034>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-48b0b5a899b2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# TODO Task 2:  Define the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Wonka/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [640 x 10], m2: [400 x 120] at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THC/generic/THCTensorMathBlas.cu:273"
     ]
    }
   ],
   "source": [
    "# train\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "model_ft = train_model(model_ft, criterion, optim, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMAIB0f8VO9M"
   },
   "source": [
    "## Task 3: Design Your Network I (20 points)\n",
    "Define your own Convolutional Network (MyNet) starting from the configuration in Task 2.2. Add following modifications and train the Network for **25** epoches. Keep the best settings for each step (for each step, record the training accuracy of the last epoch and test accuracy in your report):\n",
    "\n",
    "1. Increase the number of layers: Modify the number of convolutional layers in the network.\n",
    "2. Increase the number of filters: Modify the number of filters in each convolutional layer of the network. \n",
    "3. Modify the filter sizes in each convolutional layer. Experiment with different filter sizes (3x3, 5x5 and 7x7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpRAJHrtVO9o"
   },
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network\n",
    "class MyNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Here I use a simple AlexNet\n",
    "        # It has 5 conv layers and 3 linear layers\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.fcs = nn.sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096), nn.ReLU(),\n",
    "            nn.Linear(4096, 4096), nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        b,c,w,h=x.shape\n",
    "        x = self.fcs(x.view(b,-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkrcMarLVO9N"
   },
   "source": [
    "## Task 4: Design Your Network II (20 points)\n",
    "Keeping the best settings of Task 3, use **Dropout** in fully connected layers and Batch Normalization (choose a suitable batch size) in convolutional layers. Record the training accuracy of the last epoch and test accuracy in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biQSr45WKS86"
   },
   "source": [
    "### Design Your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpRAJHrtVO9o"
   },
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network\n",
    "class MyNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # apply bn on convs\n",
    "        # and dropout on fcs of alexnet\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.BatchNorm2d(192), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.BatchNorm2d(384), nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.fcs = nn.sequential(\n",
    "            nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(),\n",
    "            nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(),\n",
    "            nn.Dropout(), nn.Linear(4096, num_classes)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        b,c,w,h=x.shape\n",
    "        x = self.fcs(x.view(b,-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77S-thkZVO9q"
   },
   "outputs": [],
   "source": [
    "model_ft = MyNet()\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO Task 5: Optimizer\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYLl8I42VO9r"
   },
   "outputs": [],
   "source": [
    "## Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akFMVbNaVO9N"
   },
   "source": [
    "## Task 5: The Optimizer (20 points)\n",
    "Keeping the best settings of Task 4, use 3 different optimizers (SGD, ADAM and RMSProp) with 3 different learning rates (0.001, 0.01, 0.1) . Plot the loss curves (Training loss vs Training step) for each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bl7mS2igVO9v"
   },
   "source": [
    "### Testing the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtE6iv9rVO9w"
   },
   "outputs": [],
   "source": [
    "def test_model(model, load_path='saved_weight.pth'):    \n",
    "    # load the model weights\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    for phase in ['test']:\n",
    "        if phase == 'test':\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZI4TK9jVO9y"
   },
   "outputs": [],
   "source": [
    "test_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display model predictions\n",
    "## Generic function to display predictions for a few images\n",
    "\n",
    "def display_predictions(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-A_mLSoVO9O"
   },
   "source": [
    "## Task 6: Visualization (10 points)\n",
    "Visualize feature maps of the first and the last convolutional layer of your final network using **cifar_example.jpg** as input image. Show the visualization in the report.\n",
    "\n",
    "#### First layer activations\n",
    "<img src=\"https://i.imgur.com/kGB9AuP.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsbbsIGKVO9P"
   },
   "source": [
    "#### Last layer activations\n",
    "\n",
    "<img src=\"https://i.imgur.com/qelH05X.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmlGWrPwVO90"
   },
   "source": [
    "## Save the Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhQxWX8RVO91"
   },
   "outputs": [],
   "source": [
    "# TODO Task 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNX3eVEyVO94"
   },
   "outputs": [],
   "source": [
    "def transfer_single_img_to_tensor(img_path):\n",
    "    im = Image.open(img_path)\n",
    "    img = np.asarray(im)/255\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    inp = (img - mean) / std\n",
    "    inp = np.asarray(inp, dtype=np.float32)\n",
    "    inp = inp.transpose((2, 0, 1))\n",
    "    inp = np.expand_dims(inp, axis=0)\n",
    "    inp = torch.from_numpy(inp, )\n",
    "    inputs = inp.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0AqVUu9VO97"
   },
   "outputs": [],
   "source": [
    "inputs = transfer_single_img_to_tensor('example_imgs/cifar_example.jpg')\n",
    "model_ft.eval()\n",
    "with torch.no_grad():\n",
    "    model_ft(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4Y-bqt2VO99"
   },
   "outputs": [],
   "source": [
    "# Model_ft.featuremap1 and model_ft.featuremap2 should be the first and the last feature maps.\n",
    "# Add model_ft.featuremap1 and model_ft.featuremap2 at suitable places in your network\n",
    "\n",
    "feature_ouput1 = model_ft.featuremap1.transpose(1,0).cpu()\n",
    "feature_ouput2 = model_ft.featuremap2.transpose(1,0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4Qy8s4BVO9_"
   },
   "outputs": [],
   "source": [
    "def feature_imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.detach().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ofvGE8-VO-B"
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(feature_ouput1)\n",
    "feature_imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Mo1xtSzVO-E"
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(feature_ouput2)\n",
    "feature_imshow(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Image_Classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Wonka",
   "language": "python",
   "name": "wonka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
